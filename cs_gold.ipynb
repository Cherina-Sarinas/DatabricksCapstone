{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8ea304a-f479-4e51-9b32-7bc625fa49ae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "declaration of functions used"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "262b2e81-38db-44c8-854e-e86e5cf48e29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_view = \"capstone.medisure.silver_claims_view\"\n",
    "source_delta = \"capstone.medisure.silver_claims_delta_table\"\n",
    "target_table = \"capstone.medisure.gold_claims_delta_table\"\n",
    "\n",
    "# Check if Delta source exists\n",
    "delta_exists = spark.sql(f\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM system.information_schema.tables\n",
    "    WHERE table_catalog = 'capstone'\n",
    "      AND table_schema = 'medisure'\n",
    "      AND table_name = 'silver_claims_delta_table'\n",
    "\"\"\").collect()[0][0] > 0\n",
    "\n",
    "# Pick source depending on existence\n",
    "source_table = source_delta if delta_exists else source_view\n",
    "print(f\"âœ… Using {source_table} as source for MERGE\")\n",
    "\n",
    "# Ensure target exists with correct schema (empty table)\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {target_table}\n",
    "USING DELTA\n",
    "AS SELECT * FROM {source_table} WHERE 1=0\n",
    "\"\"\")\n",
    "\n",
    "# Build update set dynamically\n",
    "cols = spark.table(source_table).columns\n",
    "set_expr = \", \".join([f\"gold.{c} = silver.{c}\" for c in cols if c not in [\"ClaimID\",\"MemberID\",\"ProviderID\"]])\n",
    "\n",
    "# Merge statement\n",
    "merge_sql = f\"\"\"\n",
    "MERGE INTO {target_table} AS gold\n",
    "USING {source_table} AS silver\n",
    "ON gold.ClaimID = silver.ClaimID\n",
    "   AND gold.MemberID = silver.MemberID\n",
    "   AND gold.ProviderID = silver.ProviderID\n",
    "WHEN MATCHED THEN UPDATE SET {set_expr}\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(merge_sql)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cs_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
